{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Piano Instrument - Sound Wave & Feedfoward Neural Network (FNN)\n",
    "![Getting Started](./PianoSoundWaveFNN/images/SoundWaveFNN.jpg)\n",
    "\n",
    "****\n",
    "## Goal\n",
    "* What types of sounds are generated?\n",
    "* What are the features used to train the system?\n",
    "* What is the DL architecture employeed?\n",
    "* What are the inputs for generation?\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, PReLU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "DATASET_PATH = \"./PianoSoundWaveFNN/data/\"\n",
    "AUDIO_DATASET_PATH = os.path.join(DATASET_PATH, \"audio\")\n",
    "SAMPLE_DATASET_PATH = os.path.join(DATASET_PATH, \"sample\")\n",
    "TRAIN_DATASET_PATH = os.path.join(DATASET_PATH, \"train\")\n",
    "MODEL_PATH = os.path.join(DATASET_PATH, \"model\")\n",
    "\n",
    "WAVE_SAMPLE_RATE = 44100\n",
    "NUM_SAMPLES = 1024\n",
    "\n",
    "if not os.path.exists(SAMPLE_DATASET_PATH):\n",
    "    os.makedirs(SAMPLE_DATASET_PATH)\n",
    "\n",
    "if not os.path.exists(SAMPLE_DATASET_PATH):\n",
    "    os.makedirs(SAMPLE_DATASET_PATH)\n",
    "\n",
    "if not os.path.exists(TRAIN_DATASET_PATH):\n",
    "    os.makedirs(TRAIN_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract training dataset\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wave_samples(audio_file_path, sample_dataset_path, num_samples=NUM_SAMPLES, sr=WAVE_SAMPLE_RATE):\n",
    "    filename = os.path.basename(audio_file_path)\n",
    "    dataset_path = os.path.join(sample_dataset_path, filename + \".npy\")\n",
    "\n",
    "    if os.path.exists(dataset_path):\n",
    "        print(f\"----- getting sample dataset from {dataset_path}\")\n",
    "        w_signal = np.load(dataset_path)\n",
    "        return w_signal\n",
    "\n",
    "    dataset = []\n",
    "    print(f\"----- getting sample dataset from {audio_file_path}\")\n",
    "    signal, sr = librosa.load(audio_file_path, sr=sr)\n",
    "    num_segments = int(len(signal)/num_samples)\n",
    "            \n",
    "    # process all segments of audio file\n",
    "    for d in range(num_segments):\n",
    "        # calculate start and finish sample for current segment\n",
    "        start = num_samples * d\n",
    "        finish = start + num_samples\n",
    "        dataset.append(signal[start:finish])\n",
    "\n",
    "    w_signal = np.array(dataset).reshape(-1, num_samples)\n",
    "    print(w_signal.shape)\n",
    "\n",
    "    np.save(dataset_path, w_signal)\n",
    "    return w_signal\n",
    "    \n",
    "def create_wave_samples(audio_dataset_path, sample_dataset_path, num_samples=NUM_SAMPLES, sr=WAVE_SAMPLE_RATE):    \n",
    "    for dirpath, _, filenames in os.walk(audio_dataset_path):\n",
    "        # process all audio files in genre sub-dir\n",
    "        for f in filenames:\n",
    "            # load all audio file\n",
    "            if \"mix\" in f:\n",
    "                m_wave_file_path = os.path.join(audio_dataset_path, f)\n",
    "                m_signal = get_wave_samples(m_wave_file_path, sample_dataset_path, num_samples=num_samples, sr=sr)\n",
    "\n",
    "                t_token = f.split('_')[1]\n",
    "                t_file = t_token + '.wav'\n",
    "                t_wave_file_path = os.path.join(audio_dataset_path,  t_file)\n",
    "                t_signal = get_wave_samples(t_wave_file_path, sample_dataset_path, num_samples=num_samples, sr=sr)\n",
    "    return\n",
    "\n",
    "def create_traing_dataset(train_dataset_path, sample_dataset_path, dataset_files):   \n",
    "    F_input_file_path = os.path.join(train_dataset_path, 'input.npy')\n",
    "    F_target_file_path = os.path.join(train_dataset_path,'target.npy')\n",
    "\n",
    "    input_Dataset = np.array([])\n",
    "    target_Dataset = np.array([])\n",
    "    input_dataset = []\n",
    "    target_dataset = []\n",
    "        \n",
    "    if os.path.exists(F_input_file_path) and os.path.exists(F_input_file_path) :\n",
    "        print(f\"----- getting input dataset from {F_input_file_path}\")\n",
    "        input_Dataset = np.load(F_input_file_path)\n",
    "\n",
    "        print(f\"----- getting target dataset from {F_target_file_path}\")\n",
    "        target_Dataset = np.load(F_target_file_path)\n",
    "\n",
    "        return input_Dataset, target_Dataset\n",
    "\n",
    "    for f in dataset_files:\n",
    "        input_file_path = os.path.join(sample_dataset_path, f)\n",
    "        print(f\"----- getting input dataset from {input_file_path}\")\n",
    "        Dataset = np.load(input_file_path)\n",
    "        input_dataset.append(Dataset.tolist())\n",
    "\n",
    "        t_token = f.split('_')[1]\n",
    "        tf = t_token + '.wav.npy'\n",
    "        target_file_path = os.path.join(sample_dataset_path, tf)\n",
    "        print(f\"----- getting target dataset from {target_file_path}\")\n",
    "        Dataset = np.load(target_file_path)\n",
    "        target_dataset.append(Dataset.tolist())\n",
    "\n",
    "    num_samples = Dataset.shape[1]\n",
    "\n",
    "    input_Dataset = np.array(input_dataset).reshape(-1, num_samples)\n",
    "    target_Dataset = np.array(target_dataset).reshape(-1, num_samples)\n",
    "\n",
    "    #save to pickle file\n",
    "    print(f\"----- generating input dataset {F_input_file_path}\")\n",
    "    np.save(F_input_file_path, input_Dataset)\n",
    "\n",
    "    print(f\"----- generating target dataset {F_target_file_path}\")\n",
    "    np.save(F_target_file_path, target_Dataset)\n",
    "    return input_Dataset, target_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with Dataset\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_PATH):\n",
    "    create_wave_samples(AUDIO_DATASET_PATH, SAMPLE_DATASET_PATH, num_samples=NUM_SAMPLES, sr=WAVE_SAMPLE_RATE) \n",
    "\n",
    "    input_list = [\n",
    "            'mix_piano1_violin1.wav.npy', \\\n",
    "            'mix_piano1_violin2.wav.npy', \\\n",
    "            'mix_piano1_violin3.wav.npy', \\\n",
    "            'mix_piano2_violin1.wav.npy', \\\n",
    "            'mix_piano2_violin2.wav.npy', \\\n",
    "            'mix_piano2_violin3.wav.npy']\n",
    "\n",
    "    input, target = create_traing_dataset(TRAIN_DATASET_PATH, SAMPLE_DATASET_PATH, input_list)\n",
    "\n",
    "    # create model\n",
    "    input_shape = input[0].shape\n",
    "    input_size = input[0].shape[0]\n",
    "    output_size = target[0].shape[0]\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(input_size, input_shape=input_shape))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dense(output_size))\n",
    "    model.compile(Adam(), 'mse')\n",
    "    model.summary()\n",
    "    model.fit(input, target, epochs=5)\n",
    "    model.save(MODEL_PATH)\n",
    "else:\n",
    "    model = keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_fade_profile(batch_dim):\n",
    "    x = np.arange(batch_dim)\n",
    "    return 1 - abs(x - (batch_dim / 2)) / (batch_dim / 2)\n",
    "\n",
    "    \n",
    "def model_predict(model, input_track, num_samples):\n",
    "    dim = num_samples\n",
    "    n_batches = int(len(input_track) / dim) - 1\n",
    "    pred_batches = input_track[0:n_batches*dim].reshape((-1, dim))\n",
    "    pred_batches_shifted = input_track[dim//2:n_batches*dim + dim//2].reshape((-1, dim))\n",
    "    \n",
    "    xfp = x_fade_profile(dim)\n",
    "    x0 = np.array([xfp * batch for batch in model.predict(pred_batches)]).reshape(-1)\n",
    "    x1 = np.array([xfp * batch for batch in model.predict(pred_batches_shifted)]).reshape(-1)\n",
    "    return x0 + x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_file = os.path.join(AUDIO_DATASET_PATH, 'mix_piano2_violin2.wav')\n",
    "target_test_file = os.path.join(AUDIO_DATASET_PATH, 'piano2.wav')\n",
    "\n",
    "input_test_signal, sr = librosa.load(input_test_file, sr = WAVE_SAMPLE_RATE)\n",
    "target_test_signal, sr = librosa.load(target_test_file, sr = WAVE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(input_test_signal, rate=WAVE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(target_test_signal, rate=WAVE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciton Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(model_predict(model, input_test_signal, num_samples=NUM_SAMPLES), rate=WAVE_SAMPLE_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
