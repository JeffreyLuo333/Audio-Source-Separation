{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Piano Instrument - Sound Wave & Feedfoward Neural Network (FNN)\n",
    "![Getting Started](./PianoSoundWaveFNN/images/SoundWaveFNN.jpg)\n",
    "\n",
    "****\n",
    "## Goal\n",
    "* What types of sounds are generated?\n",
    "* What are the features used to train the system?\n",
    "* What is the DL architecture employeed?\n",
    "* What are the inputs for generation?\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, PReLU\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "\n",
    "DATASET_PATH = './PianoSoundWaveFNN/data/audio/train/piano/10'\n",
    "OUTPUT_PATH = os.path.join(DATASET_PATH, 'pkl')\n",
    "MODEL_PATH = './PianoSoundWaveFNN/model'\n",
    "\n",
    "WAVE_SAMPLE_RATE = 44100\n",
    "NUM_SAMPLES = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract training dataset\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WaveSamples_from_Wave(wave_file_path, output_data_dir, num_samples=NUM_SAMPLES, sr=WAVE_SAMPLE_RATE):\n",
    "    filename = os.path.basename(wave_file_path)\n",
    "    f_token = filename.split('.')[0]\n",
    "    data_file_name = f_token + '.pkl'\n",
    "\n",
    "    # create segment directory\n",
    "    if not os.path.exists(output_data_dir):\n",
    "        os.makedirs(output_data_dir)\n",
    "    \n",
    "    dataset_path = os.path.join(output_data_dir, data_file_name)\n",
    "    if os.path.exists(dataset_path):\n",
    "        # retrieve the data and return\n",
    "        file = open(dataset_path, 'rb')\n",
    "        print(\"----- getting dataset from {}\".format(dataset_path))\n",
    "        w_signal = pickle.load(file)\n",
    "        file.close()\n",
    "        return w_signal\n",
    "\n",
    "    dataset = []\n",
    "    signal, sr = librosa.load(wave_file_path, sr=sr)\n",
    "    num_segments = int(len(signal)/num_samples)\n",
    "            \n",
    "    # process all segments of audio file\n",
    "    for d in range(num_segments):\n",
    "        # calculate start and finish sample for current segment\n",
    "        start = num_samples * d\n",
    "        finish = start + num_samples\n",
    "        dataset.append(signal[start:finish])\n",
    "\n",
    "    w_signal = np.array(dataset).reshape(-1, num_samples)\n",
    "\n",
    "    print(w_signal.shape)\n",
    "\n",
    "    # save to pickle file\n",
    "    file = open(dataset_path, 'wb')\n",
    "    print(\"----- generating dataset {}\".format(dataset_path))\n",
    "    pickle.dump(w_signal, file)\n",
    "    file.close()\n",
    "    return w_signal\n",
    "    \n",
    "def create_WSamples(dataset_path, data_output_dir, num_samples=NUM_SAMPLES, sr=WAVE_SAMPLE_RATE):    \n",
    "    if not os.path.exists(data_output_dir):\n",
    "        os.makedirs(data_output_dir)\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(dataset_path):\n",
    "        if dirpath == data_output_dir:\n",
    "            print('----- skipping {}'.format(dirpath))\n",
    "            continue\n",
    "\n",
    "        print('----- processing {}'.format(dirpath))\n",
    "        # process all audio files in genre sub-dir\n",
    "        for f in filenames:\n",
    "            # load all audio file\n",
    "            if \"mix\" in f:\n",
    "                m_wave_file_path = os.path.join(dataset_path, f)\n",
    "                m_signal = get_WaveSamples_from_Wave(m_wave_file_path, data_output_dir, num_samples=num_samples, sr = sr)\n",
    "\n",
    "                t_token = f.split('_')[2]\n",
    "                t_file = t_token + '.wav'\n",
    "                t_wave_file_path = os.path.join(dirpath,  t_file)\n",
    "                t_signal = get_WaveSamples_from_Wave(t_wave_file_path, data_output_dir, num_samples=num_samples, sr = sr)\n",
    "    return\n",
    "\n",
    "def create_traing_dataset(dataset_path, dataset_files):   \n",
    "    F_input_file_path = os.path.join(dataset_path, 'input.pkl')\n",
    "    F_target_file_path = os.path.join(dataset_path,'target.pkl')\n",
    "\n",
    "    input_Dataset = np.array([])\n",
    "    target_Dataset = np.array([])\n",
    "    input_dataset = []\n",
    "    target_dataset = []\n",
    "        \n",
    "    if os.path.exists(F_input_file_path) and os.path.exists(F_input_file_path) :\n",
    "        print(\"----- getting input dataset from {}\".format(F_input_file_path))\n",
    "        file = open(F_input_file_path, 'rb')\n",
    "        input_Dataset = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "        print(\"----- getting target dataset from {}\".format(F_target_file_path))\n",
    "        file = open(F_target_file_path, 'rb')\n",
    "        target_Dataset = pickle.load(file)\n",
    "        file.close()\n",
    "        return input_Dataset, target_Dataset\n",
    "    \n",
    "\n",
    "    for f in dataset_files:\n",
    "        input_file_path = os.path.join(dataset_path, f)\n",
    "        print(\"----- getting input dataset from {}\".format(input_file_path))\n",
    "        file = open(input_file_path, 'rb')\n",
    "        Dataset = pickle.load(file)\n",
    "        file.close()\n",
    "        input_dataset.append(Dataset.tolist())\n",
    "\n",
    "        t_token = f.split('_')[2]\n",
    "        tf = t_token + '.pkl'\n",
    "        target_file_path = os.path.join(dataset_path, tf)\n",
    "        print(\"----- getting target dataset from {}\".format(target_file_path))\n",
    "        file = open(target_file_path, 'rb')\n",
    "        Dataset = pickle.load(file)\n",
    "        file.close()\n",
    "        target_dataset.append(Dataset.tolist())\n",
    "\n",
    "    num_samples = Dataset.shape[1]\n",
    "\n",
    "    input_Dataset = np.array(input_dataset).reshape(-1, num_samples)\n",
    "    target_Dataset = np.array(target_dataset).reshape(-1, num_samples)\n",
    "\n",
    "    #save to pickle file\n",
    "    file = open(F_input_file_path, 'wb')\n",
    "    print(\"----- generating input dataset {}\".format(F_input_file_path))\n",
    "    pickle.dump(input_Dataset, file)\n",
    "    file.close()\n",
    "\n",
    "    file = open(F_target_file_path, 'wb')\n",
    "    print(\"----- generating target dataset {}\".format(F_target_file_path))\n",
    "    pickle.dump(target_Dataset, file)\n",
    "    file.close()\n",
    "\n",
    "    return input_Dataset, target_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model with Dataset\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(MODEL_PATH):\n",
    "    create_WSamples(DATASET_PATH, OUTPUT_PATH, num_samples=NUM_SAMPLES, sr=WAVE_SAMPLE_RATE)  \n",
    "    input_list = [\n",
    "        'mix_10_piano1_10_violin1.pkl', \\\n",
    "        'mix_10_piano1_10_violin2.pkl', \\\n",
    "        'mix_10_piano1_10_violin3.pkl', \\\n",
    "        'mix_10_piano2_10_violin1.pkl', \\\n",
    "        'mix_10_piano2_10_violin2.pkl', \\\n",
    "        'mix_10_piano2_10_violin3.pkl']\n",
    "\n",
    "    input, target = create_traing_dataset(OUTPUT_PATH, input_list)\n",
    "\n",
    "    print('---------- {}'.format(input.shape))\n",
    "\n",
    "    # create model\n",
    "    input_shape = input[0].shape\n",
    "    input_size = input[0].shape[0]\n",
    "    output_size = target[0].shape[0]\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(input_size, input_shape=input_shape))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dense(512))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dense(output_size))\n",
    "    model.compile(Adam(), 'mse')\n",
    "    model.summary()\n",
    "    model.fit(input, target, epochs=10)\n",
    "    model.save(MODEL_PATH)\n",
    "else:\n",
    "    model = keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_fade_profile(batch_dim):\n",
    "    x = np.arange(batch_dim)\n",
    "    return 1 - abs(x - (batch_dim / 2)) / (batch_dim / 2)\n",
    "\n",
    "    \n",
    "def model_predict(model, input_track, num_samples):\n",
    "    dim = num_samples\n",
    "    n_batches = int(len(input_track) / dim) - 1\n",
    "    pred_batches = input_track[0:n_batches*dim].reshape((-1, dim))\n",
    "    pred_batches_shifted = input_track[dim//2:n_batches*dim + dim//2].reshape((-1, dim))\n",
    "    \n",
    "    xfp = x_fade_profile(dim)\n",
    "    x0 = np.array([xfp * batch for batch in model.predict(pred_batches)]).reshape(-1)\n",
    "    x1 = np.array([xfp * batch for batch in model.predict(pred_batches_shifted)]).reshape(-1)\n",
    "    return x0 + x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_file = os.path.join(DATASET_PATH, 'mix_10_piano2_10_violin2.wav')\n",
    "target_test_file = os.path.join(DATASET_PATH, 'piano2.wav')\n",
    "\n",
    "input_test_signal, sr = librosa.load(input_test_file, sr = WAVE_SAMPLE_RATE)\n",
    "target_test_signal, sr = librosa.load(target_test_file, sr = WAVE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(input_test_signal, rate=WAVE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(target_test_signal, rate=WAVE_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciton Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(model_predict(model, input_test_signal, num_samples=NUM_SAMPLES), rate=WAVE_SAMPLE_RATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
